---
sidebar_label: Inference Stack  
sidebar_position: 1
title: Inference Stack Overview
---
import DocCardList from '@theme/DocCardList';

<div className="page-header-with-github">
  <h1>⚡ Inference Stack Overview</h1>
  <a href="https://github.com/doublewordai/inference-stack" target="_blank" className="github-icon-link" title="View on GitHub">
    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
    </svg>
  </a>
</div>

The **Doubleword Inference Stack** provides everything needed to run scalable Large Language Models (LLMs) in your environment with ease. It includes the necessary components, configurations, and best practices to ensure optimal performance and reliability.

:::tip Deploy AI Your Way
The Inference Stack enables you to deploy AI on-premises, in your VPC, or on public cloud - giving you full control over your AI infrastructure, pricing, and uptime.
:::

## 🎯 Key Benefits

### **🏗️ Production-Ready Architecture**
Not just a single container solution - our stack provides the flexibility and scalability needed to adapt to different deployment scenarios with multiple containers unified as a service.

### **🚀 High Performance**
Optimized for inference workloads with automatic scaling, load balancing, and resource management to handle production traffic.

### **🔒 Complete Control**
Deploy in your environment without being tied to external providers. Own your AI infrastructure, pricing, and availability.

### **🎛️ Flexible Deployment**
Support for generic LLMs, domain-specific models, and privately fine-tuned models. Tailor your AI applications to meet your unique organizational needs.

### **📈 Enterprise Scale**
Built for enterprise workloads with monitoring, logging, and management tools that ensure reliable operation at scale.

---

## 🚀 Deployment Options

Ready to deploy your own AI inference infrastructure? Choose your preferred environment:

<DocCardList />
